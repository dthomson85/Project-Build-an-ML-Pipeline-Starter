{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2224904f-87f4-4b46-8377-742689a40163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip show torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52769e98-2aaf-4fff-93b8-e51de07e6f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.10.0.dev20251019+cu130\n",
      "CUDA available: True\n",
      "CUDA version: 13.0\n",
      "Number of GPUs: 1\n",
      "GPU Name: NVIDIA GeForce RTX 5060 Ti\n",
      "GPU Memory: 15.48 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e4670b-8ac4-4ce2-a8da-09246324145c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor on GPU\n",
    "x = torch.rand(5, 3).cuda()\n",
    "print(f\"Tensor device: {x.device}\")\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca72b88d-80d3-41e1-941e-1766dedb0b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2437b500-c3f5-4221-845e-899a892748d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.10.0.dev20251019+cu130\n",
      "CUDA available: True\n",
      "CUDA version: 13.0\n",
      "Number of GPUs: 1\n",
      "GPU Name: NVIDIA GeForce RTX 5060 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd63d81-3295-42a4-b130-71b5786ff1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7654a8-6a25-4162-9203-a939fe6403c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91ef5774-75b0-4522-9e95-652b2f757568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/nightly/cu130\n",
      "Requirement already satisfied: torch in /home/dan/miniconda3/envs/nyc_airbnb_dev/lib/python3.10/site-packages (2.10.0.dev20251019+cu130)\n",
      "Requirement already satisfied: torchvision in /home/dan/miniconda3/envs/nyc_airbnb_dev/lib/python3.10/site-packages (0.25.0.dev20251020+cu130)\n",
      "Requirement already satisfied: filelock in /home/dan/.local/lib/python3.10/site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/dan/.local/lib/python3.10/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /home/dan/miniconda3/envs/nyc_airbnb_dev/lib/python3.10/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /home/dan/miniconda3/envs/nyc_airbnb_dev/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/dan/.local/lib/python3.10/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /home/dan/.local/lib/python3.10/site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc==13.0.48 in /home/dan/miniconda3/envs/nyc_airbnb_dev/lib/python3.10/site-packages (from torch) (13.0.48)\n",
      "Requirement already satisfied: nvidia-cuda-runtime==13.0.48 in /home/dan/miniconda3/envs/nyc_airbnb_dev/lib/python3.10/site-packages (from torch) (13.0.48)\n",
      "Requirement already satisfied: nvidia-cuda-cupti==13.0.48 in /home/dan/miniconda3/envs/nyc_airbnb_dev/lib/python3.10/site-packages (from torch) (13.0.48)\n",
      "Requirement already satisfied: nvidia-cudnn-cu13==9.13.0.50 in /home/dan/miniconda3/envs/nyc_airbnb_dev/lib/python3.10/site-packages (from torch) (9.13.0.50)\n",
      "Requirement already satisfied: nvidia-cublas==13.0.0.19 in /home/dan/miniconda3/envs/nyc_airbnb_dev/lib/python3.10/site-packages (from torch) (13.0.0.19)\n",
      "Requirement already satisfied: nvidia-cufft==12.0.0.15 in /home/dan/miniconda3/envs/nyc_airbnb_dev/lib/python3.10/site-packages (from torch) (12.0.0.15)\n",
      "Requirement already satisfied: nvidia-curand==10.4.0.35 in /home/dan/miniconda3/envs/nyc_airbnb_dev/lib/python3.10/site-packages (from torch) (10.4.0.35)\n",
      "Requirement already satisfied: nvidia-cusolver==12.0.3.29 in /home/dan/miniconda3/envs/nyc_airbnb_dev/lib/python3.10/site-packages (from torch) (12.0.3.29)\n",
      "Requirement already satisfied: nvidia-cusparse==12.6.2.49 in /home/dan/miniconda3/envs/nyc_airbnb_dev/lib/python3.10/site-packages (from torch) (12.6.2.49)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu13==0.8.0 in /home/dan/miniconda3/envs/nyc_airbnb_dev/lib/python3.10/site-packages (from torch) (0.8.0)\n",
      "Requirement already satisfied: nvidia-nccl-cu13==2.27.7 in /home/dan/miniconda3/envs/nyc_airbnb_dev/lib/python3.10/site-packages (from torch) (2.27.7)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu13==3.3.24 in /home/dan/miniconda3/envs/nyc_airbnb_dev/lib/python3.10/site-packages (from torch) (3.3.24)\n",
      "Requirement already satisfied: nvidia-nvtx==13.0.39 in /home/dan/miniconda3/envs/nyc_airbnb_dev/lib/python3.10/site-packages (from torch) (13.0.39)\n",
      "Requirement already satisfied: nvidia-nvjitlink==13.0.39 in /home/dan/miniconda3/envs/nyc_airbnb_dev/lib/python3.10/site-packages (from torch) (13.0.39)\n",
      "Requirement already satisfied: nvidia-cufile==1.15.0.42 in /home/dan/miniconda3/envs/nyc_airbnb_dev/lib/python3.10/site-packages (from torch) (1.15.0.42)\n",
      "Requirement already satisfied: pytorch-triton==3.5.0+git7416ffcb in /home/dan/miniconda3/envs/nyc_airbnb_dev/lib/python3.10/site-packages (from torch) (3.5.0+git7416ffcb)\n",
      "Requirement already satisfied: numpy in /home/dan/.local/lib/python3.10/site-packages (from torchvision) (2.2.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/dan/.local/lib/python3.10/site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/dan/miniconda3/envs/nyc_airbnb_dev/lib/python3.10/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/dan/.local/lib/python3.10/site-packages (from jinja2->torch) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install --pre torch torchvision --index-url https://download.pytorch.org/whl/nightly/cu130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de957cfc-971f-4491-9be9-219f80b2c236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch: 2.10.0.dev20251019+cu130\n",
      "CUDA available: True\n",
      "GPU: NVIDIA GeForce RTX 5060 Ti\n",
      "GPU Memory: 15.48 GB\n",
      "\n",
      "--- Matrix size: 1000x1000 ---\n",
      "CPU time: 0.0064s\n",
      "GPU time: 0.0806s\n",
      "Speedup: 0.08x\n",
      "\n",
      "--- Matrix size: 5000x5000 ---\n",
      "CPU time: 0.5992s\n",
      "GPU time: 0.0171s\n",
      "Speedup: 35.01x\n",
      "\n",
      "--- Matrix size: 10000x10000 ---\n",
      "CPU time: 4.0003s\n",
      "GPU time: 0.1126s\n",
      "Speedup: 35.52x\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import time\n",
    "\n",
    "# Verify GPU\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\\n\")\n",
    "\n",
    "# Matrix multiplication benchmark\n",
    "sizes = [1000, 5000, 10000]\n",
    "\n",
    "for size in sizes:\n",
    "    print(f\"--- Matrix size: {size}x{size} ---\")\n",
    "    \n",
    "    # CPU\n",
    "    a_cpu = torch.randn(size, size)\n",
    "    b_cpu = torch.randn(size, size)\n",
    "    start = time.time()\n",
    "    c_cpu = torch.matmul(a_cpu, b_cpu)\n",
    "    cpu_time = time.time() - start\n",
    "    print(f\"CPU time: {cpu_time:.4f}s\")\n",
    "    \n",
    "    # GPU\n",
    "    a_gpu = torch.randn(size, size).cuda()\n",
    "    b_gpu = torch.randn(size, size).cuda()\n",
    "    torch.cuda.synchronize()  # Wait for GPU\n",
    "    start = time.time()\n",
    "    c_gpu = torch.matmul(a_gpu, b_gpu)\n",
    "    torch.cuda.synchronize()  # Wait for GPU\n",
    "    gpu_time = time.time() - start\n",
    "    print(f\"GPU time: {gpu_time:.4f}s\")\n",
    "    print(f\"Speedup: {cpu_time/gpu_time:.2f}x\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "695abc01-b85b-475f-bec1-db95c1f7991c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/nightly/cu130\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cu130/torch-2.10.0.dev20251020%2Bcu130-cp314-cp314-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Collecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cu130/torchvision-0.25.0.dev20251020%2Bcu130-cp314-cp314-manylinux_2_28_x86_64.whl.metadata (6.0 kB)\n",
      "Collecting torchaudio\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cu130/torchaudio-2.10.0.dev20251020%2Bcu130-cp314-cp314-manylinux_2_28_x86_64.whl.metadata (6.9 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting typing-extensions>=4.10.0 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting setuptools (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/setuptools-78.1.0-py3-none-any.whl.metadata (6.6 kB)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/nightly/sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=0.8.5 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting nvidia-cuda-nvrtc==13.0.48 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_cuda_nvrtc-13.0.48-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime==13.0.48 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_cuda_runtime-13.0.48-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti==13.0.48 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_cuda_cupti-13.0.48-py3-none-manylinux_2_25_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu13==9.13.0.50 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/nightly/nvidia_cudnn_cu13-9.13.0.50-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas==13.0.0.19 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_cublas-13.0.0.19-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft==12.0.0.15 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_cufft-12.0.0.15-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-curand==10.4.0.35 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_curand-10.4.0.35-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver==12.0.3.29 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_cusolver-12.0.3.29-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse==12.6.2.49 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_cusparse-12.6.2.49-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu13==0.8.0 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_cusparselt_cu13-0.8.0-py3-none-manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting nvidia-nccl-cu13==2.27.7 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_nccl_cu13-2.27.7-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvshmem-cu13==3.3.24 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_nvshmem_cu13-3.3.24-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting nvidia-nvtx==13.0.39 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_nvtx-13.0.39-py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink==13.0.39 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_nvjitlink-13.0.39-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile==1.15.0.42 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_cufile-1.15.0.42-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting pytorch-triton==3.5.0+git7416ffcb (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/pytorch_triton-3.5.0%2Bgit7416ffcb-cp314-cp314-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting numpy (from torchvision)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/numpy-2.3.4-cp314-cp314-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (62 kB)\n",
      "Collecting torch\n",
      "  Downloading https://download.pytorch.org/whl/nightly/cu130/torch-2.10.0.dev20251019%2Bcu130-cp314-cp314-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/pillow-12.0.0-cp314-cp314-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/MarkupSafe-2.1.5.tar.gz (19 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hUsing cached https://download.pytorch.org/whl/nightly/cu130/nvidia_cublas-13.0.0.19-py3-none-manylinux_2_27_x86_64.whl (419.4 MB)\n",
      "Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_cuda_cupti-13.0.48-py3-none-manylinux_2_25_x86_64.whl (10.7 MB)\n",
      "Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_cuda_nvrtc-13.0.48-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (90.2 MB)\n",
      "Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_cuda_runtime-13.0.48-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (2.2 MB)\n",
      "Using cached https://download.pytorch.org/whl/nightly/nvidia_cudnn_cu13-9.13.0.50-py3-none-manylinux_2_27_x86_64.whl (348.6 MB)\n",
      "Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_cufft-12.0.0.15-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (214.1 MB)\n",
      "Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_cufile-1.15.0.42-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_curand-10.4.0.35-py3-none-manylinux_2_27_x86_64.whl (59.5 MB)\n",
      "Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_cusolver-12.0.3.29-py3-none-manylinux_2_27_x86_64.whl (193.5 MB)\n",
      "Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_cusparse-12.6.2.49-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (140.2 MB)\n",
      "Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_cusparselt_cu13-0.8.0-py3-none-manylinux2014_x86_64.whl (169.9 MB)\n",
      "Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_nccl_cu13-2.27.7-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.9 MB)\n",
      "Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_nvjitlink-13.0.39-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (40.7 MB)\n",
      "Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_nvshmem_cu13-3.3.24-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (60.4 MB)\n",
      "Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_nvtx-13.0.39-py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (147 kB)\n",
      "Downloading https://download.pytorch.org/whl/nightly/pytorch_triton-3.5.0%2Bgit7416ffcb-cp314-cp314-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m  \u001b[33m0:00:09\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/nightly/cu130/torchvision-0.25.0.dev20251020%2Bcu130-cp314-cp314-manylinux_2_28_x86_64.whl (7.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/nightly/cu130/torch-2.10.0.dev20251019%2Bcu130-cp314-cp314-manylinux_2_28_x86_64.whl (618.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m618.6/618.6 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m  \u001b[33m0:00:36\u001b[0mm0:00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/nightly/cu130/torchaudio-2.10.0.dev20251020%2Bcu130-cp314-cp314-manylinux_2_28_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/nightly/fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Downloading https://download.pytorch.org/whl/nightly/networkx-3.5-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/nightly/pillow-12.0.0-cp314-cp314-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached https://download.pytorch.org/whl/nightly/sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Downloading https://download.pytorch.org/whl/nightly/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading https://download.pytorch.org/whl/nightly/typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Downloading https://download.pytorch.org/whl/nightly/filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Downloading https://download.pytorch.org/whl/nightly/jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading https://download.pytorch.org/whl/nightly/numpy-2.3.4-cp314-cp314-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached https://download.pytorch.org/whl/nightly/setuptools-78.1.0-py3-none-any.whl (1.3 MB)\n",
      "Building wheels for collected packages: MarkupSafe\n",
      "  Building wheel for MarkupSafe (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for MarkupSafe: filename=markupsafe-2.1.5-cp314-cp314-linux_x86_64.whl size=15122 sha256=3d940a47398571f2e7f83215fd40361d4cef6ae19af83904bf0f845d889cfa24\n",
      "  Stored in directory: /home/dan/.cache/pip/wheels/7c/1c/31/5b993d16304a5a5e2c3151f32910cdcf793501a4540504e30e\n",
      "Successfully built MarkupSafe\n",
      "Installing collected packages: nvidia-cusparselt-cu13, mpmath, typing-extensions, sympy, setuptools, pytorch-triton, pillow, nvidia-nvtx, nvidia-nvshmem-cu13, nvidia-nvjitlink, nvidia-nccl-cu13, nvidia-curand, nvidia-cufile, nvidia-cuda-runtime, nvidia-cuda-nvrtc, nvidia-cuda-cupti, nvidia-cublas, numpy, networkx, MarkupSafe, fsspec, filelock, nvidia-cusparse, nvidia-cufft, nvidia-cudnn-cu13, jinja2, nvidia-cusolver, torch, torchvision, torchaudio\n",
      "\u001b[2K  Attempting uninstall: typing-extensions━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/30\u001b[0m [mpmath]\n",
      "\u001b[2K    Found existing installation: typing_extensions 4.15.0━━━━━\u001b[0m \u001b[32m 1/30\u001b[0m [mpmath]\n",
      "\u001b[2K    Uninstalling typing_extensions-4.15.0:━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/30\u001b[0m [mpmath]\n",
      "\u001b[2K      Successfully uninstalled typing_extensions-4.15.0━━━━━━━\u001b[0m \u001b[32m 1/30\u001b[0m [mpmath]\n",
      "\u001b[2K  Attempting uninstall: setuptools━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/30\u001b[0m [sympy]\n",
      "\u001b[2K    Found existing installation: setuptools 80.9.0━━━━━━━━━━━━\u001b[0m \u001b[32m 3/30\u001b[0m [sympy]\n",
      "\u001b[2K    Uninstalling setuptools-80.9.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/30\u001b[0m [sympy]\n",
      "\u001b[2K      Successfully uninstalled setuptools-80.9.0━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/30\u001b[0m [setuptools]\n",
      "\u001b[2K  Attempting uninstall: MarkupSafe0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/30\u001b[0m [networkx]blas]rtc]3]\n",
      "\u001b[2K    Found existing installation: MarkupSafe 3.0.3━━━━━━━━━━━━━\u001b[0m \u001b[32m18/30\u001b[0m [networkx]\n",
      "\u001b[2K    Uninstalling MarkupSafe-3.0.3:90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/30\u001b[0m [networkx]\n",
      "\u001b[2K      Successfully uninstalled MarkupSafe-3.0.3━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18/30\u001b[0m [networkx]\n",
      "\u001b[2K  Attempting uninstall: jinja2━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m24/30\u001b[0m [nvidia-cudnn-cu13]\n",
      "\u001b[2K    Found existing installation: Jinja2 3.1.6╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m24/30\u001b[0m [nvidia-cudnn-cu13]\n",
      "\u001b[2K    Uninstalling Jinja2-3.1.6:━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m24/30\u001b[0m [nvidia-cudnn-cu13]\n",
      "\u001b[2K      Successfully uninstalled Jinja2-3.1.60m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m24/30\u001b[0m [nvidia-cudnn-cu13]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30/30\u001b[0m [torchaudio]0\u001b[0m [torchaudio]]ver]\n",
      "\u001b[1A\u001b[2KSuccessfully installed MarkupSafe-2.1.5 filelock-3.20.0 fsspec-2025.9.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.5 numpy-2.3.4 nvidia-cublas-13.0.0.19 nvidia-cuda-cupti-13.0.48 nvidia-cuda-nvrtc-13.0.48 nvidia-cuda-runtime-13.0.48 nvidia-cudnn-cu13-9.13.0.50 nvidia-cufft-12.0.0.15 nvidia-cufile-1.15.0.42 nvidia-curand-10.4.0.35 nvidia-cusolver-12.0.3.29 nvidia-cusparse-12.6.2.49 nvidia-cusparselt-cu13-0.8.0 nvidia-nccl-cu13-2.27.7 nvidia-nvjitlink-13.0.39 nvidia-nvshmem-cu13-3.3.24 nvidia-nvtx-13.0.39 pillow-12.0.0 pytorch-triton-3.5.0+git7416ffcb setuptools-78.1.0 sympy-1.14.0 torch-2.10.0.dev20251019+cu130 torchaudio-2.10.0.dev20251020+cu130 torchvision-0.25.0.dev20251020+cu130 typing-extensions-4.15.0\n"
     ]
    }
   ],
   "source": [
    "import sys, subprocess\n",
    "!{sys.executable} -m pip install --force-reinstall --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59b0dfd6-b9f6-46e1-8034-382e1f0228fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/nightly/cu130\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/nightly/cu130/torch-2.10.0.dev20251020%2Bcu130-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/nightly/cu130/torchvision-0.25.0.dev20251020%2Bcu130-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.0 kB)\n",
      "Collecting torchaudio\n",
      "  Using cached https://download.pytorch.org/whl/nightly/cu130/torchaudio-2.10.0.dev20251020%2Bcu130-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.9 kB)\n",
      "Collecting filelock (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/nightly/filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting typing-extensions>=4.10.0 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/nightly/typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/nightly/sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx>=2.5.1 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/nightly/networkx-3.5-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting jinja2 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/nightly/jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=0.8.5 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/nightly/fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting nvidia-cuda-nvrtc==13.0.48 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_cuda_nvrtc-13.0.48-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime==13.0.48 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_cuda_runtime-13.0.48-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti==13.0.48 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_cuda_cupti-13.0.48-py3-none-manylinux_2_25_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu13==9.13.0.50 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/nightly/nvidia_cudnn_cu13-9.13.0.50-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas==13.0.0.19 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_cublas-13.0.0.19-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft==12.0.0.15 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_cufft-12.0.0.15-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-curand==10.4.0.35 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_curand-10.4.0.35-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver==12.0.3.29 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_cusolver-12.0.3.29-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse==12.6.2.49 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_cusparse-12.6.2.49-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu13==0.8.0 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_cusparselt_cu13-0.8.0-py3-none-manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting nvidia-nccl-cu13==2.27.7 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_nccl_cu13-2.27.7-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvshmem-cu13==3.3.24 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_nvshmem_cu13-3.3.24-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting nvidia-nvtx==13.0.39 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_nvtx-13.0.39-py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink==13.0.39 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_nvjitlink-13.0.39-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile==1.15.0.42 (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_cufile-1.15.0.42-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting pytorch-triton==3.5.0+git7416ffcb (from torch)\n",
      "  Using cached https://download.pytorch.org/whl/nightly/pytorch_triton-3.5.0%2Bgit7416ffcb-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting numpy (from torchvision)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/numpy-2.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torch\n",
      "  Using cached https://download.pytorch.org/whl/nightly/cu130/torch-2.10.0.dev20251019%2Bcu130-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/pillow-12.0.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.8 kB)\n",
      "INFO: pip is looking at multiple versions of networkx to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting networkx>=2.5.1 (from torch)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch)\n",
      "  Using cached https://download.pytorch.org/whl/nightly/mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch)\n",
      "  Downloading https://download.pytorch.org/whl/nightly/MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_cublas-13.0.0.19-py3-none-manylinux_2_27_x86_64.whl (419.4 MB)\n",
      "Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_cuda_cupti-13.0.48-py3-none-manylinux_2_25_x86_64.whl (10.7 MB)\n",
      "Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_cuda_nvrtc-13.0.48-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (90.2 MB)\n",
      "Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_cuda_runtime-13.0.48-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (2.2 MB)\n",
      "Using cached https://download.pytorch.org/whl/nightly/nvidia_cudnn_cu13-9.13.0.50-py3-none-manylinux_2_27_x86_64.whl (348.6 MB)\n",
      "Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_cufft-12.0.0.15-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (214.1 MB)\n",
      "Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_cufile-1.15.0.42-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_curand-10.4.0.35-py3-none-manylinux_2_27_x86_64.whl (59.5 MB)\n",
      "Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_cusolver-12.0.3.29-py3-none-manylinux_2_27_x86_64.whl (193.5 MB)\n",
      "Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_cusparse-12.6.2.49-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (140.2 MB)\n",
      "Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_cusparselt_cu13-0.8.0-py3-none-manylinux2014_x86_64.whl (169.9 MB)\n",
      "Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_nccl_cu13-2.27.7-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.9 MB)\n",
      "Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_nvjitlink-13.0.39-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (40.7 MB)\n",
      "Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_nvshmem_cu13-3.3.24-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (60.4 MB)\n",
      "Using cached https://download.pytorch.org/whl/nightly/cu130/nvidia_nvtx-13.0.39-py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (147 kB)\n",
      "Using cached https://download.pytorch.org/whl/nightly/pytorch_triton-3.5.0%2Bgit7416ffcb-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (170.3 MB)\n",
      "Using cached https://download.pytorch.org/whl/nightly/cu130/torchvision-0.25.0.dev20251020%2Bcu130-cp310-cp310-manylinux_2_28_x86_64.whl (7.6 MB)\n",
      "Using cached https://download.pytorch.org/whl/nightly/cu130/torch-2.10.0.dev20251019%2Bcu130-cp310-cp310-manylinux_2_28_x86_64.whl (618.5 MB)\n",
      "Using cached https://download.pytorch.org/whl/nightly/cu130/torchaudio-2.10.0.dev20251020%2Bcu130-cp310-cp310-manylinux_2_28_x86_64.whl (2.1 MB)\n",
      "Using cached https://download.pytorch.org/whl/nightly/fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Downloading https://download.pytorch.org/whl/nightly/pillow-12.0.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (7.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached https://download.pytorch.org/whl/nightly/sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Using cached https://download.pytorch.org/whl/nightly/mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Using cached https://download.pytorch.org/whl/nightly/typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached https://download.pytorch.org/whl/nightly/filelock-3.20.0-py3-none-any.whl (16 kB)\n",
      "Using cached https://download.pytorch.org/whl/nightly/jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Downloading https://download.pytorch.org/whl/nightly/MarkupSafe-3.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20 kB)\n",
      "Installing collected packages: nvidia-cusparselt-cu13, mpmath, typing-extensions, sympy, pytorch-triton, pillow, nvidia-nvtx, nvidia-nvshmem-cu13, nvidia-nvjitlink, nvidia-nccl-cu13, nvidia-curand, nvidia-cufile, nvidia-cuda-runtime, nvidia-cuda-nvrtc, nvidia-cuda-cupti, nvidia-cublas, numpy, networkx, MarkupSafe, fsspec, filelock, nvidia-cusparse, nvidia-cufft, nvidia-cudnn-cu13, jinja2, nvidia-cusolver, torch, torchvision, torchaudio\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusparselt-cu13\n",
      "\u001b[2K    Found existing installation: nvidia-cusparselt-cu13 0.8.0\n",
      "\u001b[2K    Uninstalling nvidia-cusparselt-cu13-0.8.0:\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusparselt-cu13-0.8.0\n",
      "\u001b[2K  Attempting uninstall: mpmath━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/29\u001b[0m [nvidia-cusparselt-cu13]\n",
      "\u001b[2K    Found existing installation: mpmath 1.3.0[0m \u001b[32m 0/29\u001b[0m [nvidia-cusparselt-cu13]\n",
      "\u001b[2K    Uninstalling mpmath-1.3.0:━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/29\u001b[0m [nvidia-cusparselt-cu13]\n",
      "\u001b[2K      Successfully uninstalled mpmath-1.3.0━\u001b[0m \u001b[32m 0/29\u001b[0m [nvidia-cusparselt-cu13]\n",
      "\u001b[2K  Attempting uninstall: typing-extensions━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/29\u001b[0m [mpmath]\n",
      "\u001b[2K    Found existing installation: typing_extensions 4.15.0━━━━━\u001b[0m \u001b[32m 1/29\u001b[0m [mpmath]\n",
      "\u001b[2K    Uninstalling typing_extensions-4.15.0:━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/29\u001b[0m [mpmath]\n",
      "\u001b[2K      Successfully uninstalled typing_extensions-4.15.0━━━━━━━\u001b[0m \u001b[32m 1/29\u001b[0m [mpmath]\n",
      "\u001b[2K  Attempting uninstall: sympy━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/29\u001b[0m [mpmath]\n",
      "\u001b[2K    Found existing installation: sympy 1.14.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/29\u001b[0m [mpmath]\n",
      "\u001b[2K    Uninstalling sympy-1.14.0:m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/29\u001b[0m [sympy]\n",
      "\u001b[2K      Successfully uninstalled sympy-1.14.0━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/29\u001b[0m [sympy]\n",
      "\u001b[2K  Attempting uninstall: pytorch-triton━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/29\u001b[0m [sympy]\n",
      "\u001b[2K    Found existing installation: pytorch-triton 3.5.0+git7416ffcbm \u001b[32m 3/29\u001b[0m [sympy]\n",
      "\u001b[2K    Uninstalling pytorch-triton-3.5.0+git7416ffcb:━━━━━━━━━━━━\u001b[0m \u001b[32m 3/29\u001b[0m [sympy]\n",
      "\u001b[2K      Successfully uninstalled pytorch-triton-3.5.0+git7416ffcb[0m \u001b[32m 3/29\u001b[0m [sympy]\n",
      "\u001b[2K  Attempting uninstall: pillow0m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/29\u001b[0m [pytorch-triton]\n",
      "\u001b[2K    Found existing installation: pillow 11.3.0━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/29\u001b[0m [pytorch-triton]\n",
      "\u001b[2K    Uninstalling pillow-11.3.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/29\u001b[0m [pytorch-triton]\n",
      "\u001b[2K      Successfully uninstalled pillow-11.3.0━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 4/29\u001b[0m [pytorch-triton]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvtx━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/29\u001b[0m [pillow]ton]\n",
      "\u001b[2K    Found existing installation: nvidia-nvtx 13.0.39━━━━━━━━━━\u001b[0m \u001b[32m 5/29\u001b[0m [pillow]\n",
      "\u001b[2K    Uninstalling nvidia-nvtx-13.0.39:━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/29\u001b[0m [pillow]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvtx-13.0.39━━━━━━━━━━━━\u001b[0m \u001b[32m 5/29\u001b[0m [pillow]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvshmem-cu13━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/29\u001b[0m [pillow]\n",
      "\u001b[2K    Found existing installation: nvidia-nvshmem-cu13 3.3.24━━━\u001b[0m \u001b[32m 5/29\u001b[0m [pillow]\n",
      "\u001b[2K    Uninstalling nvidia-nvshmem-cu13-3.3.24:━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/29\u001b[0m [pillow]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvshmem-cu13-3.3.24━━━━━\u001b[0m \u001b[32m 5/29\u001b[0m [pillow]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvjitlink━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/29\u001b[0m [nvidia-nvshmem-cu13]\n",
      "\u001b[2K    Found existing installation: nvidia-nvjitlink 13.0.39━━━━━\u001b[0m \u001b[32m 7/29\u001b[0m [nvidia-nvshmem-cu13]\n",
      "\u001b[2K    Uninstalling nvidia-nvjitlink-13.0.39:━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/29\u001b[0m [nvidia-nvshmem-cu13]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvjitlink-13.0.39━━━━━━━\u001b[0m \u001b[32m 7/29\u001b[0m [nvidia-nvshmem-cu13]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nccl-cu13━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/29\u001b[0m [nvidia-nvjitlink]\n",
      "\u001b[2K    Found existing installation: nvidia-nccl-cu13 2.27.7━━━━━━\u001b[0m \u001b[32m 8/29\u001b[0m [nvidia-nvjitlink]\n",
      "\u001b[2K    Uninstalling nvidia-nccl-cu13-2.27.7:━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/29\u001b[0m [nvidia-nvjitlink]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nccl-cu13-2.27.7━━━━━━━━\u001b[0m \u001b[32m 8/29\u001b[0m [nvidia-nvjitlink]\n",
      "\u001b[2K  Attempting uninstall: nvidia-curand0m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/29\u001b[0m [nvidia-nccl-cu13]\n",
      "\u001b[2K    Found existing installation: nvidia-curand 10.4.0.35━━━━━━\u001b[0m \u001b[32m 9/29\u001b[0m [nvidia-nccl-cu13]\n",
      "\u001b[2K    Uninstalling nvidia-curand-10.4.0.35:━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/29\u001b[0m [nvidia-nccl-cu13]\n",
      "\u001b[2K      Successfully uninstalled nvidia-curand-10.4.0.35━━━━━━━━\u001b[0m \u001b[32m 9/29\u001b[0m [nvidia-nccl-cu13]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cufile90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/29\u001b[0m [nvidia-curand]\n",
      "\u001b[2K    Found existing installation: nvidia-cufile 1.15.0.42━━━━━━\u001b[0m \u001b[32m10/29\u001b[0m [nvidia-curand]\n",
      "\u001b[2K    Uninstalling nvidia-cufile-1.15.0.42:━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/29\u001b[0m [nvidia-curand]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cufile-1.15.0.42━━━━━━━━\u001b[0m \u001b[32m10/29\u001b[0m [nvidia-curand]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-runtime━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/29\u001b[0m [nvidia-curand]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-runtime 13.0.48━━\u001b[0m \u001b[32m10/29\u001b[0m [nvidia-curand]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-runtime-13.0.48:━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/29\u001b[0m [nvidia-curand]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-runtime-13.0.48━━━━\u001b[0m \u001b[32m10/29\u001b[0m [nvidia-curand]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-nvrtc━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/29\u001b[0m [nvidia-curand]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-nvrtc 13.0.48━━━━\u001b[0m \u001b[32m10/29\u001b[0m [nvidia-curand]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-nvrtc-13.0.48:━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/29\u001b[0m [nvidia-curand]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-nvrtc-13.0.48━━━━━━\u001b[0m \u001b[32m10/29\u001b[0m [nvidia-curand]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-cupti90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/29\u001b[0m [nvidia-cuda-nvrtc]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-cupti 13.0.48━━━━\u001b[0m \u001b[32m13/29\u001b[0m [nvidia-cuda-nvrtc]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-cupti-13.0.48:━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/29\u001b[0m [nvidia-cuda-nvrtc]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-cupti-13.0.48━━━━━━\u001b[0m \u001b[32m13/29\u001b[0m [nvidia-cuda-nvrtc]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cublas\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/29\u001b[0m [nvidia-cuda-cupti]\n",
      "\u001b[2K    Found existing installation: nvidia-cublas 13.0.0.19━━━━━━\u001b[0m \u001b[32m14/29\u001b[0m [nvidia-cuda-cupti]\n",
      "\u001b[2K    Uninstalling nvidia-cublas-13.0.0.19:m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/29\u001b[0m [nvidia-cuda-cupti]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cublas-13.0.0.19━━━━━━━━\u001b[0m \u001b[32m14/29\u001b[0m [nvidia-cuda-cupti]\n",
      "\u001b[2K  Attempting uninstall: numpy[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/29\u001b[0m [nvidia-cublas]\n",
      "\u001b[2K    Found existing installation: numpy 2.2.6━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/29\u001b[0m [nvidia-cublas]\n",
      "\u001b[2K    Uninstalling numpy-2.2.6:[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/29\u001b[0m [nvidia-cublas]\n",
      "\u001b[2K      Successfully uninstalled numpy-2.2.6m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/29\u001b[0m [nvidia-cublas]\n",
      "\u001b[2K  Attempting uninstall: networkx0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/29\u001b[0m [numpy]las]\n",
      "\u001b[2K    Found existing installation: networkx 3.4.2━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/29\u001b[0m [numpy]\n",
      "\u001b[2K    Uninstalling networkx-3.4.2:90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/29\u001b[0m [numpy]\n",
      "\u001b[2K      Successfully uninstalled networkx-3.4.2━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16/29\u001b[0m [numpy]\n",
      "\u001b[2K  Attempting uninstall: MarkupSafem\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/29\u001b[0m [networkx]\n",
      "\u001b[2K    Found existing installation: MarkupSafe 3.0.3━━━━━━━━━━━━━\u001b[0m \u001b[32m17/29\u001b[0m [networkx]\n",
      "\u001b[2K    Uninstalling MarkupSafe-3.0.3:0m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/29\u001b[0m [networkx]\n",
      "\u001b[2K      Successfully uninstalled MarkupSafe-3.0.3━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/29\u001b[0m [networkx]\n",
      "\u001b[2K  Attempting uninstall: fsspecm\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/29\u001b[0m [networkx]\n",
      "\u001b[2K    Found existing installation: fsspec 2025.9.0━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/29\u001b[0m [networkx]\n",
      "\u001b[2K    Uninstalling fsspec-2025.9.0:90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/29\u001b[0m [networkx]\n",
      "\u001b[2K      Successfully uninstalled fsspec-2025.9.0━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/29\u001b[0m [networkx]\n",
      "\u001b[2K  Attempting uninstall: filelock[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/29\u001b[0m [networkx]\n",
      "\u001b[2K    Found existing installation: filelock 3.19.1━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/29\u001b[0m [networkx]\n",
      "\u001b[2K    Uninstalling filelock-3.19.1:90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/29\u001b[0m [networkx]\n",
      "\u001b[2K      Successfully uninstalled filelock-3.19.1━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/29\u001b[0m [networkx]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusparse0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/29\u001b[0m [networkx]\n",
      "\u001b[2K    Found existing installation: nvidia-cusparse 12.6.2.49━━━━\u001b[0m \u001b[32m17/29\u001b[0m [networkx]\n",
      "\u001b[2K    Uninstalling nvidia-cusparse-12.6.2.49:90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/29\u001b[0m [networkx]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusparse-12.6.2.49━━━━━━\u001b[0m \u001b[32m17/29\u001b[0m [networkx]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cufft\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m21/29\u001b[0m [nvidia-cusparse]\n",
      "\u001b[2K    Found existing installation: nvidia-cufft 12.0.0.15━━━━━━━\u001b[0m \u001b[32m21/29\u001b[0m [nvidia-cusparse]\n",
      "\u001b[2K    Uninstalling nvidia-cufft-12.0.0.15:m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m21/29\u001b[0m [nvidia-cusparse]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cufft-12.0.0.15━━━━━━━━━\u001b[0m \u001b[32m21/29\u001b[0m [nvidia-cusparse]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cudnn-cu13m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m22/29\u001b[0m [nvidia-cufft]\n",
      "\u001b[2K    Found existing installation: nvidia-cudnn-cu13 9.13.0.50━━\u001b[0m \u001b[32m22/29\u001b[0m [nvidia-cufft]\n",
      "\u001b[2K    Uninstalling nvidia-cudnn-cu13-9.13.0.50:[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m22/29\u001b[0m [nvidia-cufft]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cudnn-cu13-9.13.0.50━━━━\u001b[0m \u001b[32m22/29\u001b[0m [nvidia-cufft]\n",
      "\u001b[2K  Attempting uninstall: jinja2━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m23/29\u001b[0m [nvidia-cudnn-cu13]\n",
      "\u001b[2K    Found existing installation: Jinja2 3.1.6\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m23/29\u001b[0m [nvidia-cudnn-cu13]\n",
      "\u001b[2K    Uninstalling Jinja2-3.1.6:━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m23/29\u001b[0m [nvidia-cudnn-cu13]\n",
      "\u001b[2K      Successfully uninstalled Jinja2-3.1.6m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m23/29\u001b[0m [nvidia-cudnn-cu13]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusolver\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m23/29\u001b[0m [nvidia-cudnn-cu13]\n",
      "\u001b[2K    Found existing installation: nvidia-cusolver 12.0.3.29━━━━\u001b[0m \u001b[32m23/29\u001b[0m [nvidia-cudnn-cu13]\n",
      "\u001b[2K    Uninstalling nvidia-cusolver-12.0.3.29:m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m23/29\u001b[0m [nvidia-cudnn-cu13]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusolver-12.0.3.29━━━━━━\u001b[0m \u001b[32m23/29\u001b[0m [nvidia-cudnn-cu13]\n",
      "\u001b[2K  Attempting uninstall: torch━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m25/29\u001b[0m [nvidia-cusolver]\n",
      "\u001b[2K    Found existing installation: torch 2.10.0.dev20251019+cu130[0m \u001b[32m25/29\u001b[0m [nvidia-cusolver]\n",
      "\u001b[2K    Uninstalling torch-2.10.0.dev20251019+cu130:[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m26/29\u001b[0m [torch]olver]\n",
      "\u001b[2K      Successfully uninstalled torch-2.10.0.dev20251019+cu130m━━━━\u001b[0m \u001b[32m26/29\u001b[0m [torch]\n",
      "\u001b[2K  Attempting uninstall: torchvision━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m26/29\u001b[0m [torch]\n",
      "\u001b[2K    Found existing installation: torchvision 0.25.0.dev20251020+cu13032m26/29\u001b[0m [torch]\n",
      "\u001b[2K    Uninstalling torchvision-0.25.0.dev20251020+cu130:[90m━━━━\u001b[0m \u001b[32m26/29\u001b[0m [torch]\n",
      "\u001b[2K      Successfully uninstalled torchvision-0.25.0.dev20251020+cu130\u001b[32m26/29\u001b[0m [torch]\n",
      "\u001b[2K  Attempting uninstall: torchaudio━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m27/29\u001b[0m [torchvision]\n",
      "\u001b[2K    Found existing installation: torchaudio 2.10.0.dev20251020+cu130[32m27/29\u001b[0m [torchvision]\n",
      "\u001b[2K    Uninstalling torchaudio-2.10.0.dev20251020+cu130:0m\u001b[90m━━\u001b[0m \u001b[32m27/29\u001b[0m [torchvision]\n",
      "\u001b[2K      Successfully uninstalled torchaudio-2.10.0.dev20251020+cu130 \u001b[32m27/29\u001b[0m [torchvision]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29/29\u001b[0m [torchaudio]9\u001b[0m [torchaudio]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "anthropic 0.37.1 requires distro<2,>=1.7.0, which is not installed.\n",
      "azure-identity 1.25.0 requires cryptography>=2.5, which is not installed.\n",
      "azure-storage-blob 12.26.0 requires cryptography>=2.1.4, which is not installed.\n",
      "fastapi-sso 0.16.0 requires oauthlib>=3.1.0, which is not installed.\n",
      "openai 2.1.0 requires distro<2,>=1.7.0, which is not installed.\n",
      "semgrep 1.140.0 requires colorama~=0.4.0, which is not installed.\n",
      "fastapi 0.115.14 requires starlette<0.47.0,>=0.40.0, but you have starlette 0.37.2 which is incompatible.\n",
      "open-interpreter 0.4.3 requires platformdirs<5.0.0,>=4.2.0, but you have platformdirs 3.11.0 which is incompatible.\n",
      "open-interpreter 0.4.3 requires tiktoken<0.8.0,>=0.7.0, but you have tiktoken 0.11.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed MarkupSafe-3.0.2 filelock-3.20.0 fsspec-2025.9.0 jinja2-3.1.6 mpmath-1.3.0 networkx-3.4.2 numpy-2.1.2 nvidia-cublas-13.0.0.19 nvidia-cuda-cupti-13.0.48 nvidia-cuda-nvrtc-13.0.48 nvidia-cuda-runtime-13.0.48 nvidia-cudnn-cu13-9.13.0.50 nvidia-cufft-12.0.0.15 nvidia-cufile-1.15.0.42 nvidia-curand-10.4.0.35 nvidia-cusolver-12.0.3.29 nvidia-cusparse-12.6.2.49 nvidia-cusparselt-cu13-0.8.0 nvidia-nccl-cu13-2.27.7 nvidia-nvjitlink-13.0.39 nvidia-nvshmem-cu13-3.3.24 nvidia-nvtx-13.0.39 pillow-10.3.0 pytorch-triton-3.5.0+git7416ffcb sympy-1.14.0 torch-2.10.0.dev20251019+cu130 torchaudio-2.10.0.dev20251020+cu130 torchvision-0.25.0.dev20251020+cu130 typing-extensions-4.15.0\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install --force-reinstall --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65c82899-513a-48f4-b298-e36f53da557a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARM-UP TEST: Finding primes up to 10 million...\n",
      "Finding primes up to 10,000,000 using GPU...\n",
      "GPU: NVIDIA GeForce RTX 5060 Ti\n",
      "GPU Memory: 15.48 GB\n",
      "\n",
      "Running Sieve of Eratosthenes on GPU...\n",
      "\n",
      "==================================================\n",
      "Found 664,579 prime numbers up to 10,000,000\n",
      "Time elapsed: 0.11 seconds\n",
      "Rate: 87,157,629 numbers/second\n",
      "==================================================\n",
      "\n",
      "First 50 primes: [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97, 101, 103, 107, 109, 113, 127, 131, 137, 139, 149, 151, 157, 163, 167, 173, 179, 181, 191, 193, 197, 199, 211, 223, 227, 229]\n",
      "\n",
      "\n",
      "==================================================\n",
      "MAIN CALCULATION: 1 BILLION\n",
      "==================================================\n",
      "\n",
      "Finding primes up to 1,000,000,000 using GPU...\n",
      "GPU: NVIDIA GeForce RTX 5060 Ti\n",
      "GPU Memory: 15.48 GB\n",
      "\n",
      "Running Sieve of Eratosthenes on GPU...\n",
      "Progress: 10,000 / 31,623\n",
      "Progress: 20,000 / 31,623\n",
      "Progress: 30,000 / 31,623\n",
      "\n",
      "==================================================\n",
      "Found 50,847,534 prime numbers up to 1,000,000,000\n",
      "Time elapsed: 1.11 seconds\n",
      "Rate: 901,022,524 numbers/second\n",
      "==================================================\n",
      "\n",
      "Last 20 primes found:\n",
      "  999,999,491\n",
      "  999,999,503\n",
      "  999,999,527\n",
      "  999,999,541\n",
      "  999,999,587\n",
      "  999,999,599\n",
      "  999,999,607\n",
      "  999,999,613\n",
      "  999,999,667\n",
      "  999,999,677\n",
      "  999,999,733\n",
      "  999,999,739\n",
      "  999,999,751\n",
      "  999,999,757\n",
      "  999,999,761\n",
      "  999,999,797\n",
      "  999,999,883\n",
      "  999,999,893\n",
      "  999,999,929\n",
      "  999,999,937\n",
      "\n",
      "🎉 GPU calculation complete!\n"
     ]
    }
   ],
   "source": [
    "%run prime_finder_gpu.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f247caba-587d-4038-b6ea-2a0b22f061f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 CALCULATING PRIMES UP TO 1 TRILLION 🚀\n",
      "\n",
      "Finding primes up to 1,000,000,000,000 using segmented GPU sieve\n",
      "GPU: NVIDIA GeForce RTX 5060 Ti\n",
      "Segment size: 100,000,000\n",
      "\n",
      "Step 1: Finding base primes up to 1,000,001...\n",
      "Found 78,498 base primes\n",
      "\n",
      "Step 2: Processing 10000 segments...\n",
      "\n",
      "Segment 1/10000: [1,000,001 - 101,000,000]\n"
     ]
    }
   ],
   "source": [
    "%run prime_finder_trillion.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93de035e-0e8a-4347-8f91-1b64b95911bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "🚀 CALCULATING PRIMES UP TO 1 TRILLION 🚀\n",
      "======================================================================\n",
      "\n",
      "Finding primes up to 1,000,000,000,000 using segmented GPU sieve\n",
      "GPU: NVIDIA GeForce RTX 5060 Ti\n",
      "GPU Memory: 15.48 GB\n",
      "Segment size: 1,000,000,000 (0.93 GB per segment)\n",
      "\n",
      "Step 1: Finding base primes up to 1,000,001...\n",
      "Found 78,498 base primes in 0.13s\n",
      "\n",
      "Step 2: Processing 1000 segments of 1 billion numbers each...\n",
      "\n",
      "======================================================================\n",
      "Segment 1/1000 [1,000,001 - 1,001,000,000]\n",
      "  ✓ Primes found: 50,817,191 | Total: 50,895,689\n",
      "  ⏱️  Segment time: 3.46s | Speed: 289,410,024 nums/sec\n",
      "  📊 Progress: 0.1% | Elapsed: 3.6s | ETA: 3579.2s\n",
      "----------------------------------------------------------------------\n",
      "Segment 2/1000 [1,001,000,001 - 2,001,000,000]\n",
      "  ✓ Primes found: 47,373,501 | Total: 98,269,190\n",
      "  ⏱️  Segment time: 3.51s | Speed: 285,294,663 nums/sec\n",
      "  📊 Progress: 0.2% | Elapsed: 7.1s | ETA: 3543.9s\n",
      "----------------------------------------------------------------------\n",
      "Segment 3/1000 [2,001,000,001 - 3,001,000,000]\n",
      "  ✓ Primes found: 46,226,227 | Total: 144,495,417\n",
      "  ⏱️  Segment time: 3.44s | Speed: 291,074,717 nums/sec\n",
      "  📊 Progress: 0.3% | Elapsed: 10.6s | ETA: 3506.7s\n",
      "----------------------------------------------------------------------\n",
      "Segment 4/1000 [3,001,000,001 - 4,001,000,000]\n",
      "  ✓ Primes found: 45,511,561 | Total: 190,006,978\n",
      "  ⏱️  Segment time: 3.52s | Speed: 284,350,571 nums/sec\n",
      "  📊 Progress: 0.4% | Elapsed: 14.1s | ETA: 3506.6s\n",
      "----------------------------------------------------------------------\n",
      "Segment 5/1000 [4,001,000,001 - 5,001,000,000]\n",
      "  ✓ Primes found: 44,992,008 | Total: 234,998,986\n",
      "  ⏱️  Segment time: 3.54s | Speed: 282,557,071 nums/sec\n",
      "  📊 Progress: 0.5% | Elapsed: 17.6s | ETA: 3509.5s\n",
      "----------------------------------------------------------------------\n",
      "Segment 6/1000 [5,001,000,001 - 6,001,000,000]\n",
      "  ✓ Primes found: 44,590,714 | Total: 279,589,700\n",
      "  ⏱️  Segment time: 3.40s | Speed: 293,766,083 nums/sec\n",
      "  📊 Progress: 0.6% | Elapsed: 21.1s | ETA: 3488.0s\n",
      "----------------------------------------------------------------------\n",
      "Segment 7/1000 [6,001,000,001 - 7,001,000,000]\n",
      "  ✓ Primes found: 44,258,750 | Total: 323,848,450\n",
      "  ⏱️  Segment time: 3.45s | Speed: 289,679,903 nums/sec\n",
      "  📊 Progress: 0.7% | Elapsed: 24.5s | ETA: 3478.4s\n",
      "----------------------------------------------------------------------\n",
      "Segment 8/1000 [7,001,000,001 - 8,001,000,000]\n",
      "  ✓ Primes found: 43,979,009 | Total: 367,827,459\n",
      "  ⏱️  Segment time: 3.55s | Speed: 281,311,530 nums/sec\n",
      "  📊 Progress: 0.8% | Elapsed: 28.1s | ETA: 3483.1s\n",
      "----------------------------------------------------------------------\n",
      "Segment 9/1000 [8,001,000,001 - 9,001,000,000]\n",
      "  ✓ Primes found: 43,739,292 | Total: 411,566,751\n",
      "  ⏱️  Segment time: 3.54s | Speed: 282,354,893 nums/sec\n",
      "  📊 Progress: 0.9% | Elapsed: 31.6s | ETA: 3484.4s\n",
      "----------------------------------------------------------------------\n",
      "Segment 10/1000 [9,001,000,001 - 10,001,000,000]\n",
      "  ✓ Primes found: 43,529,187 | Total: 455,095,938\n",
      "  ⏱️  Segment time: 3.50s | Speed: 285,568,973 nums/sec\n",
      "  📊 Progress: 1.0% | Elapsed: 35.2s | ETA: 3480.9s\n",
      "----------------------------------------------------------------------\n",
      "Segment 11/1000 [10,001,000,001 - 11,001,000,000]\n",
      "  ✓ Primes found: 43,335,599 | Total: 498,431,537\n",
      "  ⏱️  Segment time: 3.54s | Speed: 282,590,100 nums/sec\n",
      "  📊 Progress: 1.1% | Elapsed: 38.7s | ETA: 3480.7s\n",
      "----------------------------------------------------------------------\n",
      "Segment 12/1000 [11,001,000,001 - 12,001,000,000]\n",
      "  ✓ Primes found: 43,167,352 | Total: 541,598,889\n",
      "  ⏱️  Segment time: 3.51s | Speed: 284,706,588 nums/sec\n",
      "  📊 Progress: 1.2% | Elapsed: 42.2s | ETA: 3477.8s\n",
      "----------------------------------------------------------------------\n",
      "Segment 13/1000 [12,001,000,001 - 13,001,000,000]\n",
      "  ✓ Primes found: 43,014,273 | Total: 584,613,162\n",
      "  ⏱️  Segment time: 3.47s | Speed: 288,548,932 nums/sec\n",
      "  📊 Progress: 1.3% | Elapsed: 45.7s | ETA: 3471.2s\n",
      "----------------------------------------------------------------------\n",
      "Segment 14/1000 [13,001,000,001 - 14,001,000,000]\n",
      "  ✓ Primes found: 42,870,097 | Total: 627,483,259\n",
      "  ⏱️  Segment time: 3.53s | Speed: 283,404,108 nums/sec\n",
      "  📊 Progress: 1.4% | Elapsed: 49.3s | ETA: 3469.5s\n",
      "----------------------------------------------------------------------\n",
      "Segment 15/1000 [14,001,000,001 - 15,001,000,000]\n",
      "  ✓ Primes found: 42,740,201 | Total: 670,223,460\n",
      "  ⏱️  Segment time: 3.42s | Speed: 292,470,912 nums/sec\n",
      "  📊 Progress: 1.5% | Elapsed: 52.7s | ETA: 3460.3s\n",
      "----------------------------------------------------------------------\n",
      "Segment 16/1000 [15,001,000,001 - 16,001,000,000]\n",
      "  ✓ Primes found: 42,618,817 | Total: 712,842,277\n",
      "  ⏱️  Segment time: 3.55s | Speed: 281,305,285 nums/sec\n",
      "  📊 Progress: 1.6% | Elapsed: 56.3s | ETA: 3460.3s\n",
      "----------------------------------------------------------------------\n",
      "Segment 17/1000 [16,001,000,001 - 17,001,000,000]\n",
      "  ✓ Primes found: 42,506,123 | Total: 755,348,400\n",
      "  ⏱️  Segment time: 3.50s | Speed: 286,032,213 nums/sec\n",
      "  📊 Progress: 1.7% | Elapsed: 59.8s | ETA: 3456.4s\n",
      "----------------------------------------------------------------------\n",
      "Segment 18/1000 [17,001,000,001 - 18,001,000,000]\n",
      "  ✓ Primes found: 42,397,219 | Total: 797,745,619\n",
      "  ⏱️  Segment time: 3.57s | Speed: 280,450,287 nums/sec\n",
      "  📊 Progress: 1.8% | Elapsed: 63.4s | ETA: 3456.3s\n",
      "----------------------------------------------------------------------\n",
      "Segment 19/1000 [18,001,000,001 - 19,001,000,000]\n",
      "  ✓ Primes found: 42,296,712 | Total: 840,042,331\n",
      "  ⏱️  Segment time: 3.42s | Speed: 292,723,426 nums/sec\n",
      "  📊 Progress: 1.9% | Elapsed: 66.8s | ETA: 3448.2s\n",
      "----------------------------------------------------------------------\n",
      "Segment 20/1000 [19,001,000,001 - 20,001,000,000]\n",
      "  ✓ Primes found: 42,206,455 | Total: 882,248,786\n",
      "  ⏱️  Segment time: 3.44s | Speed: 290,834,879 nums/sec\n",
      "  📊 Progress: 2.0% | Elapsed: 70.2s | ETA: 3441.7s\n",
      "----------------------------------------------------------------------\n",
      "Segment 21/1000 [20,001,000,001 - 21,001,000,000]\n",
      "  ✓ Primes found: 42,117,962 | Total: 924,366,748\n",
      "  ⏱️  Segment time: 3.42s | Speed: 292,479,437 nums/sec\n",
      "  📊 Progress: 2.1% | Elapsed: 73.7s | ETA: 3434.5s\n",
      "----------------------------------------------------------------------\n",
      "Segment 22/1000 [21,001,000,001 - 22,001,000,000]\n",
      "  ✓ Primes found: 42,033,419 | Total: 966,400,167\n",
      "  ⏱️  Segment time: 3.55s | Speed: 281,865,835 nums/sec\n",
      "  📊 Progress: 2.2% | Elapsed: 77.2s | ETA: 3433.4s\n",
      "----------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Project-Build-an-ML-Pipeline-Starter/prime_finder_trillion.py:105\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m🚀 CALCULATING PRIMES UP TO 1 TRILLION 🚀\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    103\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m=\u001b[39m\u001b[33m\"\u001b[39m*\u001b[32m70\u001b[39m + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m105\u001b[39m total = \u001b[43msegmented_sieve_gpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msegment_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1_000_000_000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m💡 FUN FACT: There are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtotal\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m primes below 1 trillion!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    108\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m    That\u001b[39m\u001b[33m'\u001b[39m\u001b[33ms approximately 1 in every 26 numbers!\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Project-Build-an-ML-Pipeline-Starter/prime_finder_trillion.py:64\u001b[39m, in \u001b[36msegmented_sieve_gpu\u001b[39m\u001b[34m(limit, segment_size)\u001b[39m\n\u001b[32m     62\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m start <= high:\n\u001b[32m     63\u001b[39m         indices = torch.arange(start - low, seg_size, prime, device=\u001b[33m'\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m         segment[indices] = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# Count primes in this segment\u001b[39;00m\n\u001b[32m     67\u001b[39m seg_prime_count = segment.sum().item()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "%run prime_finder_trillion.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0dc593-007d-4992-8737-bdfb3d3cbf63",
   "metadata": {},
   "source": [
    "# This is Reddit Sans Font"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1a61e8-a5ba-4603-9009-550b0a6ca35f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (nyc_airbnb_dev)",
   "language": "python",
   "name": "nyc_airbnb_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
